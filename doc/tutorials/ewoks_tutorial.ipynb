{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "221ed84f-a561-49be-8d80-db89e2539793",
   "metadata": {},
   "source": [
    "# Execute a darfix workflow without GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbd4e8c-a04d-4a6e-a7ee-3401df9035b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from orangecontrib.darfix import tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2440e89e-b5c0-4509-ab32-ac9910e29893",
   "metadata": {},
   "source": [
    "## from CLI using ewoks\n",
    "\n",
    "You can execute darfix workflows as any ewoks workflow using the [ewoks execute](https://ewokscore.readthedocs.io/en/latest/) command. Parameter values can be provided with the `--parameter` options (or the `-p` alias).\n",
    "For example, we want to execute a workflow named `my_darfix_workflow.ows` by setting two parameters: the detector HDF5 dataset and the HDF5 positioner dataset (aka metadata). For this, we can use the following command:\n",
    "\n",
    "```bash\n",
    "ewoks execute /home/esrf/payno/Documents/my_darfix_workflow.ows --parameter filenames=silx:///data/scisoft/darfix/datasets/bliss_hdf5/Silicon_111_reflection_0003/Silicon_111_reflection_0003.h5?path=/1.1/instrument/pco_ff/data --parameter metadata_url=silx:///data/scisoft/darfix/datasets/bliss_hdf5/Silicon_111_reflection_0003/Silicon_111_reflection_0003.h5?path=/1.1/instrument/positioners\n",
    "```\n",
    "\n",
    "Warning: the HDF5 dataset must be provided as [silx URL](https://www.silx.org/doc/silx/latest/modules/io/url.html#silx.io.url.DataUrl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27cc9f2-42b1-42e7-9f54-9041eb6aa74b",
   "metadata": {},
   "source": [
    "## From Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1eb7541-ae44-48fa-a70c-a8326590b604",
   "metadata": {},
   "source": [
    "### step 1: Define task arguments which are not defined in the workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6e61a4-9440-428e-accd-a3e39f79dd6c",
   "metadata": {},
   "source": [
    "in this example we will focus about HDF5 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a20726b-9799-4510-8ea2-c4d2ecf5d98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/tmp/darfix\"\n",
    "os.makedirs(root_dir, exist_ok=True)\n",
    "hdf5_file = os.path.join(tutorials.__path__[0], \"hdf5_dataset\", \"strain.hdf5\")\n",
    "assert os.path.exists(hdf5_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236329ef-43ab-49d0-aec5-d7d8e16c22d7",
   "metadata": {},
   "source": [
    "### step2: Execute the workflow\n",
    "\n",
    "For more information on executing ewoks workflows: https://workflow.gitlab-pages.esrf.fr/ewoks/ewoks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9615db1d-fa55-4f32-b088-9d35c8cc35c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ewoks import execute_graph\n",
    "\n",
    "graph = os.path.join(tutorials.__path__[0], \"darfix_example_hdf.ows\")\n",
    "results = execute_graph(\n",
    "    graph,\n",
    "    inputs=[\n",
    "        {\n",
    "            \"name\": \"raw_input_file\",\n",
    "            \"value\": hdf5_file,\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"raw_detector_data_path\",\n",
    "            \"value\": \"/1.1/instrument/my_detector/data\",\n",
    "        },\n",
    "        {\"name\": \"raw_metadata_path\", \"value\": \"/1.1/instrument/positioners\"},\n",
    "        {\n",
    "            \"name\": \"in_memory\",\n",
    "            \"value\": True,\n",
    "        },\n",
    "    ],\n",
    "    output_tasks=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf86750-b893-488e-bd9a-3fe0c741812f",
   "metadata": {},
   "source": [
    "### Inspect the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ed6acc-d816-43d0-8139-b836c8a579f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for node_id, task in results.items():\n",
    "    assert task.succeeded, f\"task {node_id} failed\"\n",
    "    print(task.get_output_values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5765046d-4ce4-4dc7-b7f8-bc4bd711ab4f",
   "metadata": {},
   "source": [
    "#### Note\n",
    "\n",
    "The same can be done for EDF datasets. In this case the, `metadata_url` parameter should be omitted and the `filenames` parameter will contain the list of the EDF image paths:\n",
    "\n",
    "```python\n",
    "from glob import glob\n",
    "root_dir = \"/tmp/darfix\"\n",
    "os.makedirs(root_dir, exist_ok=True)\n",
    "filenames = glob(os.path.join(tutorials.__path__[0], \"*.edf\"))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527c3701-3d8c-4a90-a41d-5a3fcc6d1fbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "darfix",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
